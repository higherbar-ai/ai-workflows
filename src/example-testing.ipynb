{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Example testing notebook\n",
    "\n",
    "This notebook provides an example of how you can test LLM-assisted document conversion vs. the alternative. Before attempting to run, be sure to set up your Python environment using the code in `initial-setup.ipynb` and configure the `.ini` file as discussed below.\n",
    "\n",
    "The notebook begins by loading credentials and configuration from an `.ini` file stored in `~/.hbai/ai-workflows.ini`. The `~` in the path refers to the current user's home directory, and the `.ini` file contents should follow this format (with keys, models, and paths as appropriate):\n",
    "\n",
    "    [openai]\n",
    "    openai-api-key=keyhere-with-sk-on-front\n",
    "    openai-model=gpt-4o\n",
    "    azure-api-key=keyhere-or-blank\n",
    "    azure-api-base=azure-base-url-here\n",
    "    azure-api-engine=gpt-4o\n",
    "    azure-api-version=2024-02-01\n",
    "\n",
    "    [anthropic]\n",
    "    anthropic-api-key=keyhere\n",
    "    anthropic-model=\n",
    "\n",
    "    [aws]\n",
    "    aws-profile=\n",
    "    bedrock-model=\n",
    "    bedrock-region=us-east-1\n",
    "\n",
    "    [langsmith]\n",
    "    langsmith-api-key=leave-blank-unless-you're-using-langsmith\n",
    "\n",
    "    [files]\n",
    "    input-dir=~/Files/ai-workflows/inputs\n",
    "    output-dir=~/Files/ai-workflows/outputs\n",
    "\n",
    "You can set up either OpenAI, Azure, Anthropic, or Bedrock as the LLM, leaving settings for the other LLMs blank. You also don't need to supply a Langsmith API key unless you're using Langsmith. The `input-dir` and `output-dir` settings are used to specify the directories where input and output files are stored, respectively.\n",
    "\n",
    "## Installing dependencies\n",
    "\n",
    "This next code block installs the dependencies required for this notebook."
   ],
   "id": "8b6627c85f89ca21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# install requirements specific to this notebook (only need to run once in a given environment)\n",
    "%pip install pandas rapidfuzz"
   ],
   "id": "bce858aa2decda1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Initializing\n",
    "\n",
    "This next code block initializes the notebook, reading parameters from the configuration file and initializing an LLM interface."
   ],
   "id": "fadda0abd86e1dbb"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# for convenience, auto-reload modules when they've changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "import configparser\n",
    "import os\n",
    "from ai_workflows.llm_utilities import LLMInterface \n",
    "\n",
    "# set log level to WARNING\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# load credentials and other configuration from a local ini file\n",
    "inifile_location = os.path.expanduser(\"~/.hbai/ai-workflows.ini\")\n",
    "inifile = configparser.RawConfigParser()\n",
    "inifile.read(inifile_location)\n",
    "\n",
    "# load configuration\n",
    "openai_api_key = inifile.get(\"openai\", \"openai-api-key\")\n",
    "openai_model = inifile.get(\"openai\", \"openai-model\")\n",
    "azure_api_key = inifile.get(\"openai\", \"azure-api-key\")\n",
    "azure_api_base = inifile.get(\"openai\", \"azure-api-base\")\n",
    "azure_api_engine = inifile.get(\"openai\", \"azure-api-engine\")\n",
    "azure_api_version = inifile.get(\"openai\", \"azure-api-version\")\n",
    "anthropic_api_key = inifile.get(\"anthropic\", \"anthropic-api-key\")\n",
    "anthropic_model = inifile.get(\"anthropic\", \"anthropic-model\")\n",
    "aws_profile = inifile.get(\"aws\", \"aws-profile\")\n",
    "bedrock_model = inifile.get(\"aws\", \"bedrock-model\")\n",
    "bedrock_region = inifile.get(\"aws\", \"bedrock-region\")\n",
    "input_dir = os.path.expanduser(inifile.get(\"files\", \"input-dir\"))\n",
    "output_dir = os.path.expanduser(inifile.get(\"files\", \"output-dir\"))\n",
    "langsmith_api_key = inifile.get(\"langsmith\", \"langsmith-api-key\")\n",
    "\n",
    "# initialize LangSmith API (if key specified)\n",
    "if langsmith_api_key:\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"local\"\n",
    "    os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = langsmith_api_key\n",
    "\n",
    "# initialize the LLM\n",
    "llm = LLMInterface(\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_model=openai_model,\n",
    "    azure_api_key=azure_api_key,\n",
    "    azure_api_base=azure_api_base,\n",
    "    azure_api_engine=azure_api_engine,\n",
    "    azure_api_version=azure_api_version,\n",
    "    langsmith_api_key=langsmith_api_key,\n",
    "    anthropic_api_key=anthropic_api_key,\n",
    "    anthropic_model=anthropic_model,\n",
    "    bedrock_model=bedrock_model,\n",
    "    bedrock_region=bedrock_region,\n",
    "    bedrock_aws_profile=aws_profile\n",
    ")\n",
    "\n",
    "# report results\n",
    "print(\"Local configuration loaded, LLM initialized.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Converting input documents to Markdown\n",
    "\n",
    "This next code block runs through all the files in the configured input directory and converts them to Markdown, saving the Markdown files in the output directory. It also converts the files without the LLM (adding a \"-no-llm\" suffix to the base name of each output file) so that you can see the difference betweeen LLM-assisted and regular conversion."
   ],
   "id": "2d8772f49725280f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# use document_utilities to convert all files in the input directory\n",
    "from ai_workflows.document_utilities import DocumentInterface\n",
    "\n",
    "# initialize the document interface\n",
    "doc = DocumentInterface(llm_interface=llm)\n",
    "doc_no_llm = DocumentInterface()\n",
    "\n",
    "# convert all files in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if os.path.isfile(os.path.join(input_dir, filename)) and not filename.startswith('.'):\n",
    "        print(f\"Converting {filename} to markdown...\")\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        markdown = doc.convert_to_markdown(input_path, use_text=False)\n",
    "\n",
    "        # write the markdown to the output directory\n",
    "        output_path = os.path.join(output_dir, os.path.splitext(os.path.basename(filename))[0] + '.md')\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(markdown)\n",
    "        print(f\"Conversion complete (w/ LLM). Markdown saved to {output_path}\")\n",
    "\n",
    "        # now convert again without the LLM\n",
    "        markdown_no_llm = doc_no_llm.convert_to_markdown(input_path)\n",
    "        output_path = os.path.join(output_dir, os.path.splitext(os.path.basename(filename))[0] + '-no-llm.md')\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(markdown_no_llm)\n",
    "        print(f\"Conversion complete (w/o LLM). Markdown saved to {output_path}\")"
   ],
   "id": "a93b4c932412ba5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Customized version of \"the Laterite method\" — thanks, Laterite!\n",
    "\n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz, process\n",
    "import unicodedata\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import os\n",
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalizes text by:\n",
    "    - Converting to NFC form.\n",
    "    - Replacing specific problematic characters.\n",
    "    \"\"\"\n",
    "    \n",
    "    # normalize Unicode characters to NFC form\n",
    "    text = unicodedata.normalize('NFC', text)\n",
    "    \n",
    "    # replace specific problematic characters\n",
    "    replacements = {\n",
    "        \"â€™\": \"'\",  # Right single quotation mark\n",
    "        \"â€œ\": '\"',  # Left double quotation mark\n",
    "        \"â€\": '\"',  # Right double quotation mark\n",
    "        \"â€“\": '-',  # En dash\n",
    "        \"â€”\": '-',  # Em dash\n",
    "        \"…\": '...',  # Ellipsis\n",
    "    }\n",
    "    for wrong, correct in replacements.items():\n",
    "        text = text.replace(wrong, correct)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def segment_text(text, segment_type='paragraph', min_words=2):\n",
    "    \"\"\"\n",
    "    Segments text into paragraphs, sentences, or lines and ensures each segment has a minimum number of words.\n",
    "    \"\"\"\n",
    "    \n",
    "    if segment_type == 'sentence':\n",
    "        segments = sent_tokenize(text)\n",
    "    elif segment_type == 'paragraph':\n",
    "        paragraphs = re.split(r'\\n{2,}', text)\n",
    "        if len(paragraphs) == 1:\n",
    "            # fall back to lines if no paragraph breaks are found\n",
    "            paragraphs = text.split('\\n')\n",
    "        segments = [para.strip() for para in paragraphs if para.strip()]\n",
    "    elif segment_type == 'line':\n",
    "        segments = text.split('\\n')\n",
    "    else:\n",
    "        raise ValueError(\"segment_type must be 'sentence', 'paragraph', or 'line'\")\n",
    "\n",
    "    # strip each segment\n",
    "    segments = [seg.strip() for seg in segments]\n",
    "\n",
    "    # eliminate empty segments\n",
    "    segments = [seg for seg in segments if seg]\n",
    "    \n",
    "    return combine_short_segments(segments, min_words)\n",
    "\n",
    "def combine_short_segments(segments: list[str], min_words: int) -> list[str]:\n",
    "   \"\"\"\n",
    "   Combine segments that have fewer than min_words words with either their\n",
    "   previous or next neighbor, choosing the shorter neighbor when both exist.\n",
    "   \"\"\"\n",
    "   \n",
    "   if not segments:\n",
    "       return []\n",
    "   \n",
    "   result = segments.copy()\n",
    "   i = 0\n",
    "   \n",
    "   while i < len(result):\n",
    "       word_count = len(result[i].split())\n",
    "       \n",
    "       if word_count < min_words:\n",
    "           if i == len(result) - 1 and i > 0:\n",
    "               # if this is the last segment and there's a previous one\n",
    "               result[i-1] = f\"{result[i-1]} {result[i]}\"\n",
    "               result.pop(i)\n",
    "               i -= 1  # move back to check the combined segment           \n",
    "           elif i == 0 and i < len(result) - 1:\n",
    "               # if this is the first segment and there's a next one\n",
    "               result[i] = f\"{result[i]} {result[i+1]}\"\n",
    "               result.pop(i+1)\n",
    "               i -= 1  # recheck this position\n",
    "           elif 0 < i < len(result) - 1:\n",
    "               # if we have both previous and next segments\n",
    "               prev_len = len(result[i-1].split())\n",
    "               next_len = len(result[i+1].split())\n",
    "               \n",
    "               if prev_len <= next_len:\n",
    "                   # combine with the shorter neighbor (previous)\n",
    "                   result[i-1] = f\"{result[i-1]} {result[i]}\"\n",
    "                   result.pop(i)\n",
    "                   i -= 1  # move back to check the combined segment\n",
    "               else:\n",
    "                   # combine with the shorter neighbor (next)\n",
    "                   result[i] = f\"{result[i]} {result[i+1]}\"\n",
    "                   result.pop(i+1)\n",
    "                   i -= 1  # recheck this position\n",
    "           \n",
    "       i += 1\n",
    "   \n",
    "   return result\n",
    "\n",
    "def find_best_match(word_seg, n_grams, similarity_threshold):\n",
    "    \"\"\"\n",
    "    Finds the best matching n-gram above the given similarity threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    match = process.extractOne( # type: ignore\n",
    "        word_seg,\n",
    "        n_grams,\n",
    "        scorer=fuzz.ratio,\n",
    "        score_cutoff=similarity_threshold\n",
    "    )\n",
    "    return match\n",
    "\n",
    "def compare_text(baseline_text: str, comparison_text: str, output_loc: str, baseline_filename: str, comparison_filename: str):\n",
    "    \"\"\"\n",
    "    Compares comparison_text against baseline_text using tiered similarity thresholds.\n",
    "    \n",
    "    Returns Tuple with overall similarity score and unmatched text.\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove extensions from filenames\n",
    "    baseline_name = os.path.splitext(baseline_filename)[0]\n",
    "    comparison_name = os.path.splitext(comparison_filename)[0]\n",
    "    \n",
    "    # start by normalizing both strings\n",
    "    baseline_text = normalize_text(baseline_text)\n",
    "    comparison_text = normalize_text(comparison_text)\n",
    "    \n",
    "    # output normalized text to files\n",
    "    with open(os.path.join(output_loc, f\"{baseline_name}-normalized.txt\"), \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(baseline_text)\n",
    "    with open(os.path.join(output_loc, f\"{comparison_name}-normalized.txt\"), \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(comparison_text)\n",
    "\n",
    "    # segment the baseline text into paragraphs\n",
    "    word_segments = segment_text(baseline_text, segment_type='line', min_words=5)\n",
    "    print(f\"Number of segments in baseline text: {len(word_segments)}\")\n",
    "\n",
    "    # tokenize the comparison text into words for n-gram generation\n",
    "    comparison_words = comparison_text.split()\n",
    "\n",
    "    # initialize mapping table and track unmatched segments\n",
    "    mapping_table = []\n",
    "    unmatched_segments = [(i + 1, seg) for i, seg in enumerate(word_segments)]\n",
    "    \n",
    "    # define similarity thresholds for tiered matching\n",
    "    similarity_thresholds = [100, 95, 90, 85, 80, 75, 70]\n",
    "    \n",
    "    # process each similarity threshold in turn\n",
    "    for threshold in similarity_thresholds:\n",
    "        if not unmatched_segments:\n",
    "            # if we're done, break out of the loop\n",
    "            break\n",
    "            \n",
    "        still_unmatched = []        \n",
    "        for seg_num, word_seg in unmatched_segments:\n",
    "            # count the number of words in the baseline segment\n",
    "            n = len(word_seg.split())\n",
    "            \n",
    "            # calculate the range for 10% variation\n",
    "            min_length = max(1, int(n * 0.9))  # ensure minimum length is at least 1\n",
    "            max_length = int(n * 1.1)\n",
    "            \n",
    "            # generate n-grams of varying lengths within the 10% range\n",
    "            n_grams = []\n",
    "            for length in range(min_length, max_length + 1):\n",
    "                n_grams.extend([' '.join(comparison_words[j:j+length]) for j in range(len(comparison_words) - length + 1)])\n",
    "            \n",
    "            # remove empty n-grams\n",
    "            n_grams = [ng for ng in n_grams if ng.strip()]\n",
    "\n",
    "            # find best match at current threshold\n",
    "            match = find_best_match(word_seg, n_grams, threshold)\n",
    "            \n",
    "            if match:\n",
    "                matched_text = match[0]\n",
    "                similarity = match[1]\n",
    "                \n",
    "                # remove the matched text from comparison_words\n",
    "                matched_words = matched_text.split()\n",
    "                start_index = None\n",
    "                for i in range(len(comparison_words) - len(matched_words) + 1):\n",
    "                    if comparison_words[i:i+len(matched_words)] == matched_words:\n",
    "                        start_index = i\n",
    "                        break\n",
    "                if start_index is None:\n",
    "                    # if no match is found, raise exception\n",
    "                    raise ValueError(\"Matched words not found in comparison_words\")\n",
    "                del comparison_words[start_index:start_index+len(matched_words)]                \n",
    "                             \n",
    "                # add mapping to output table           \n",
    "                mapping_table.append({\n",
    "                    'Segment Number': seg_num,\n",
    "                    'Baseline Segment': word_seg,\n",
    "                    'Matched Comparison Text': matched_text,\n",
    "                    'Similarity Score (%)': similarity\n",
    "                })\n",
    "            else:\n",
    "                still_unmatched.append((seg_num, word_seg))\n",
    "        \n",
    "        # keep track of unmatched segments for next iteration\n",
    "        unmatched_segments = still_unmatched\n",
    "\n",
    "    # add any remaining unmatched segments to mapping table\n",
    "    for seg_num, word_seg in unmatched_segments:\n",
    "        mapping_table.append({\n",
    "            'Segment Number': seg_num,\n",
    "            'Baseline Segment': word_seg,\n",
    "            'Matched Comparison Text': '',\n",
    "            'Similarity Score (%)': 0\n",
    "        })\n",
    "\n",
    "    # sort mapping table by segment number\n",
    "    mapping_table.sort(key=lambda x: x['Segment Number'])\n",
    "\n",
    "    # output matching summary\n",
    "    print(\"\\nMatching summary:\\n\")\n",
    "    prev_threshold = 1000\n",
    "    for i in range(len(similarity_thresholds)):\n",
    "        lower_bound = similarity_thresholds[i]\n",
    "        upper_bound = prev_threshold\n",
    "        count = sum(1 for mapping in mapping_table if lower_bound <= mapping['Similarity Score (%)'] < upper_bound)\n",
    "        if upper_bound == 1000:\n",
    "            print(f\"Segments with {lower_bound}% similarity: {count}\")\n",
    "        else:\n",
    "            print(f\"Segments with {lower_bound}-{upper_bound-1}.99% similarity: {count}\")\n",
    "        prev_threshold = lower_bound\n",
    "    no_match_count = sum(1 for mapping in mapping_table if mapping['Similarity Score (%)'] == 0)\n",
    "    print(f\"Segments with no match: {no_match_count}\")        \n",
    "\n",
    "    # compute overall similarity score as weighted average across all segments, weighting by segment length\n",
    "    total_size = 0\n",
    "    total_weighted_similarity = 0\n",
    "    for mapping in mapping_table:\n",
    "        # add mapping to running totals\n",
    "        total_size += len(mapping['Baseline Segment'])\n",
    "        total_weighted_similarity += len(mapping['Baseline Segment']) * mapping['Similarity Score (%)']\n",
    "    # calculate final weighted score\n",
    "    overall_similarity = total_weighted_similarity / total_size if total_size > 0 else 0\n",
    "    \n",
    "    # output total similarity score\n",
    "    print(f\"\\nOverall Similarity Score: {overall_similarity:.2f}%\")\n",
    "    \n",
    "    # reconstruct comparison text without matched segments\n",
    "    remaining_comparison_text = ' '.join(word for word in comparison_words if word)\n",
    "    # strip leading and trailing whitespace\n",
    "    remaining_comparison_text = remaining_comparison_text.strip()\n",
    "        \n",
    "    # report and add unmatched text to mapping table\n",
    "    if remaining_comparison_text:\n",
    "        print(f\"\\nFound {len(remaining_comparison_text)} characters of unmatched text: {remaining_comparison_text}\")\n",
    "        mapping_table.append({\n",
    "            'Segment Number': f'99999',\n",
    "            'Baseline Segment': '',\n",
    "            'Matched Comparison Text': remaining_comparison_text,\n",
    "            'Similarity Score (%)': 0\n",
    "        })\n",
    "    else:\n",
    "        print(\"\\nNo unmatched text found.\")\n",
    "    \n",
    "    # export mapping table\n",
    "    if mapping_table:\n",
    "        df = pd.DataFrame(mapping_table)\n",
    "        output_table_path = os.path.join(output_loc, f\"{comparison_name}-mapping-table.xlsx\")\n",
    "        try:\n",
    "            df.to_excel(output_table_path, index=False, engine='openpyxl')\n",
    "            print(f\"\\nMapping table has been exported to {output_table_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError exporting mapping table: {e}\")\n",
    "    else:\n",
    "        print(\"\\nNo mapping information to export.\")\n",
    "    \n",
    "    return overall_similarity, remaining_comparison_text"
   ],
   "id": "fbece719602faf2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Comparing Markdown documents\n",
    "\n",
    "The next several sections have code to compare the LLM and no-LLM versions of the Markdown outputs. They are a work-in-progress.\n",
    "\n",
    "Many thanks to Laterite for contributing ideas and code for this evaluation process.\n",
    "\n",
    "For each compared filename, this comparison process will output:\n",
    "\n",
    "1. **In the output window**: Summary results, including a weighted similarity score and \"extra text\" in the LLM version\n",
    "2. **filename-mapping-table.xlsx**: A mapping table showing the similarity of each segment in the LLM version to the no-LLM version, with extra text at the end\n",
    "3. **filename-baseline-normalized.txt**: The normalized text of the no-LLM version\n",
    "4. **filename-comparison-normalized.txt**: The normalized text of the LLM version\n",
    "\n",
    "A final summary of results at the end will include the average similarity score and a list of all similarity scores."
   ],
   "id": "d1e02188ca9ac38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# loop through input files and compare the -no-llm version to the LLM version of the output files\n",
    "similarity_scores = []\n",
    "for filename in os.listdir(input_dir):\n",
    "    if os.path.isfile(os.path.join(input_dir, filename)) and not filename.startswith('.'):\n",
    "        output_path1 = os.path.join(output_dir, os.path.splitext(os.path.basename(filename))[0] + '.md')\n",
    "        output_path2 = os.path.join(output_dir, os.path.splitext(os.path.basename(filename))[0] + '-no-llm.md')\n",
    "\n",
    "        print(f\"\\n\\nComparing {output_path1} to {output_path2}...\")\n",
    "        print()\n",
    "        with open(output_path1, 'r') as f:\n",
    "            md1 = f.read()\n",
    "        with open(output_path2, 'r') as f:\n",
    "            md2 = f.read()\n",
    "\n",
    "        # compare using the Laterite method\n",
    "        similarity_score, extra_text = compare_text(DocumentInterface.markdown_to_text(md2), DocumentInterface.markdown_to_text(md1), output_dir, os.path.basename(output_path2), os.path.basename(output_path1))\n",
    "        \n",
    "        # add similarity score to list\n",
    "        similarity_scores.append(similarity_score)\n",
    "\n",
    "# output summary results, including average similarity score and list of scores\n",
    "print(\"\\n\\nSUMMARY RESULTS:\\n\")\n",
    "print(f\"Average similarity score: {sum(similarity_scores) / len(similarity_scores):.2f}%\\n\")\n",
    "print(f\"Similarity scores: {similarity_scores}\")"
   ],
   "id": "cb34052874464dc9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
