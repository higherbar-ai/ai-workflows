{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Example testing notebook\n",
    "\n",
    "This notebook provides an example of how you can test LLM-assisted document conversion vs. the alternative. Before attempting to run, be sure to set up your Python environment using the code in `initial-setup.ipynb` and configure the `.ini` file as discussed below.\n",
    "\n",
    "The notebook begins by loading credentials and configuration from an `.ini` file stored in `~/.hbai/ai-workflows.ini`. The `~` in the path refers to the current user's home directory, and the `.ini` file contents should follow this format (with keys, models, and paths as appropriate):\n",
    "\n",
    "    [openai]\n",
    "    openai-api-key=keyhere-with-sk-on-front\n",
    "    openai-model=gpt-4o\n",
    "    azure-api-key=keyhere-or-blank\n",
    "    azure-api-base=azure-base-url-here\n",
    "    azure-api-engine=gpt-4o\n",
    "    azure-api-version=2024-02-01\n",
    "\n",
    "    [anthropic]\n",
    "    anthropic-api-key=keyhere\n",
    "    anthropic-model=\n",
    "\n",
    "    [aws]\n",
    "    aws-profile=\n",
    "    bedrock-model=\n",
    "    bedrock-region=us-east-1\n",
    "\n",
    "    [langsmith]\n",
    "    langsmith-api-key=leave-blank-unless-you're-using-langsmith\n",
    "\n",
    "    [files]\n",
    "    input-dir=~/Files/ai-workflows/inputs\n",
    "    output-dir=~/Files/ai-workflows/outputs\n",
    "\n",
    "You can set up either OpenAI, Azure, Anthropic, or Bedrock as the LLM, leaving settings for the other LLMs blank. You also don't need to supply a Langsmith API key unless you're using Langsmith. The `input-dir` and `output-dir` settings are used to specify the directories where input and output files are stored, respectively.\n",
    "\n",
    "## Initializing\n",
    "\n",
    "This next code block initializes the notebook, reading parameters from the configuration file and initializing an LLM interface."
   ],
   "id": "8b6627c85f89ca21"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-06T18:34:38.828149Z",
     "start_time": "2024-11-06T18:34:37.010925Z"
    }
   },
   "source": [
    "# for convenience, auto-reload modules when they've changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "import configparser\n",
    "import os\n",
    "from ai_workflows.llm_utilities import LLMInterface \n",
    "\n",
    "# set log level to WARNING\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# load credentials and other configuration from a local ini file\n",
    "inifile_location = os.path.expanduser(\"~/.hbai/ai-workflows.ini\")\n",
    "inifile = configparser.RawConfigParser()\n",
    "inifile.read(inifile_location)\n",
    "\n",
    "# load configuration\n",
    "openai_api_key = inifile.get(\"openai\", \"openai-api-key\")\n",
    "openai_model = inifile.get(\"openai\", \"openai-model\")\n",
    "azure_api_key = inifile.get(\"openai\", \"azure-api-key\")\n",
    "azure_api_base = inifile.get(\"openai\", \"azure-api-base\")\n",
    "azure_api_engine = inifile.get(\"openai\", \"azure-api-engine\")\n",
    "azure_api_version = inifile.get(\"openai\", \"azure-api-version\")\n",
    "anthropic_api_key = inifile.get(\"anthropic\", \"anthropic-api-key\")\n",
    "anthropic_model = inifile.get(\"anthropic\", \"anthropic-model\")\n",
    "aws_profile = inifile.get(\"aws\", \"aws-profile\")\n",
    "bedrock_model = inifile.get(\"aws\", \"bedrock-model\")\n",
    "bedrock_region = inifile.get(\"aws\", \"bedrock-region\")\n",
    "input_dir = os.path.expanduser(inifile.get(\"files\", \"input-dir\"))\n",
    "output_dir = os.path.expanduser(inifile.get(\"files\", \"output-dir\"))\n",
    "langsmith_api_key = inifile.get(\"langsmith\", \"langsmith-api-key\")\n",
    "\n",
    "# initialize LangSmith API (if key specified)\n",
    "if langsmith_api_key:\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"local\"\n",
    "    os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = langsmith_api_key\n",
    "\n",
    "# initialize the LLM\n",
    "llm = LLMInterface(\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_model=openai_model,\n",
    "    azure_api_key=azure_api_key,\n",
    "    azure_api_base=azure_api_base,\n",
    "    azure_api_engine=azure_api_engine,\n",
    "    azure_api_version=azure_api_version,\n",
    "    langsmith_api_key=langsmith_api_key,\n",
    "    anthropic_api_key=anthropic_api_key,\n",
    "    anthropic_model=anthropic_model,\n",
    "    bedrock_model=bedrock_model,\n",
    "    bedrock_region=bedrock_region,\n",
    "    bedrock_aws_profile=aws_profile\n",
    ")\n",
    "\n",
    "# report results\n",
    "print(\"Local configuration loaded, LLM initialized.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local configuration loaded, LLM initialized.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Converting input documents to Markdown\n",
    "\n",
    "This next code block runs through all the files in the configured input directory and converts them to Markdown, saving the Markdown files in the output directory. It also converts the files without the LLM (adding a \"-no-llm\" suffix to the base name of each output file) so that you can see the difference betweeen LLM-assisted and regular conversion."
   ],
   "id": "2d8772f49725280f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T18:35:49.048491Z",
     "start_time": "2024-11-06T18:34:38.832203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# use document_utilities to convert all files in the input directory\n",
    "from ai_workflows.document_utilities import DocumentInterface\n",
    "\n",
    "# initialize the document interface\n",
    "doc = DocumentInterface(llm_interface=llm)\n",
    "doc_no_llm = DocumentInterface()\n",
    "\n",
    "# convert all files in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if os.path.isfile(os.path.join(input_dir, filename)) and not filename.startswith('.') and not filename.endswith('.md'):\n",
    "        print(f\"Converting {filename} to markdown...\")\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        markdown = doc.convert_to_markdown(input_path)\n",
    "\n",
    "        # write the markdown to the output directory\n",
    "        output_path = os.path.join(output_dir, os.path.splitext(os.path.basename(filename))[0] + '.md')\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(markdown)\n",
    "\n",
    "        # now convert again without the LLM\n",
    "        markdown_no_llm = doc_no_llm.convert_to_markdown(input_path)\n",
    "        output_path = os.path.join(output_dir, os.path.splitext(os.path.basename(filename))[0] + '-no-llm.md')\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(markdown_no_llm)        \n",
    "\n",
    "        print(f\"Conversion complete. Markdown saved to {output_path}\")"
   ],
   "id": "a93b4c932412ba5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting test2.pdf to markdown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing PDF /Users/crobert/Files/ai-workflows/inputs/test2.pdf from 17 images\n",
      "INFO:root:Processing PDF page 1: Size=(1241, 1754), Mode=RGB\n",
      "INFO:httpx:HTTP Request: POST https://hbai-openai-useast2.openai.azure.com//openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Extracted JSON for page 1: {\n",
      "  \"elements\": [\n",
      "    {\n",
      "      \"type\": \"image\",\n",
      "      \"content\": \"The image shows a stylized illustration of a group of people holding a large sign. The sign displays the text 'CARBON MARKET WATCH' with a logo resembling an eye. Below the group, the text 'ANNUAL REPORT 2023' is prominently displayed. The background is a solid teal color.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "INFO:root:Processing PDF page 2: Size=(1240, 1754), Mode=RGB\n",
      "INFO:httpx:HTTP Request: POST https://hbai-openai-useast2.openai.azure.com//openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Extracted JSON for page 2: {\n",
      "  \"elements\": [\n",
      "    {\n",
      "      \"type\": \"body_text_section\",\n",
      "      \"content\": \"# CARBON MARKET WATCH ANNUAL REPORT 2023\\n\\n**Date of publication:** May 2024\\n\\nCarbon Market Watch\\nAvenue Marnix 17,\\nB-1000 Brussels, Belgium\\n\\n**Website:** www.carbonmarketwatch.org\\n**Email:** info@carbonmarketwatch.org\\n**Twitter:** @CarbonMrktWatch\\n**LinkedIn:** https://www.linkedin.com/company/carbon-market-watch/\\n\\nReport by Khaled Diab, Communications Director\\nGraphic design by L\\u00e9a Moisan (moisan.lea@gmail.com)\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"page_footer\",\n",
      "      \"content\": \"2  CARBON MARKET WATCH\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "INFO:root:Processing PDF page 3: Size=(1241, 1754), Mode=RGB\n",
      "INFO:httpx:HTTP Request: POST https://hbai-openai-useast2.openai.azure.com//openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Extracted JSON for page 3: {\n",
      "  \"elements\": [\n",
      "    {\n",
      "      \"type\": \"body_text_section\",\n",
      "      \"content\": \"### OUR MISSION\\n\\nCarbon Market Watch exists to ensure that carbon pricing and other climate policies drive a just transition towards zero-carbon societies. Given the urgency of halting the climate breakdown, we want market-based climate policy tools to fulfil their promise and be used in wise combination with regulatory and incentivising measures.\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"body_text_section\",\n",
      "      \"content\": \"### OUR APPROACH\\n\\nEvidence-based advocacy is central to our work. We watch critically over the design and implementation of market-based climate policy tools in particular and call out where these underperform, lead to environmental damage or ignore people\\u2019s rights.\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"page_footer\",\n",
      "      \"content\": \"2023 ANNUAL REPORT 3\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "INFO:root:Processing PDF page 4: Size=(1240, 1754), Mode=RGB\n",
      "INFO:httpx:HTTP Request: POST https://hbai-openai-useast2.openai.azure.com//openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Extracted JSON for page 4: {\n",
      "  \"elements\": [\n",
      "    {\n",
      "      \"type\": \"image\",\n",
      "      \"content\": \"An illustration of the Earth with blue flames scattered across various continents. A green diagonal stripe crosses the image from the top left to the bottom right. Blue droplets are depicted falling around the Earth.\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"page_footer\",\n",
      "      \"content\": \"4  CARBON MARKET WATCH\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "INFO:root:Processing PDF page 5: Size=(1241, 1754), Mode=RGB\n",
      "INFO:httpx:HTTP Request: POST https://hbai-openai-useast2.openai.azure.com//openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Extracted JSON for page 5: {\n",
      "  \"elements\": [\n",
      "    {\n",
      "      \"type\": \"body_text_section\",\n",
      "      \"content\": \"# FOREWORD\\n\\nIt was another year of record-breaking temperatures. Not only was 2023 the hottest year on record by a stretch, but each month from June onwards was the warmest from that month ever recorded. Moreover, every day was 1\\u00b0C or more warmer than the pre-industrial norm for that day and the world came perilously close to the 1.5\\u00b0C limit it is seeking not to overshoot.\\n\\nNot to sound like a broken record, but what these broken records illustrate is that the heat is on to tackle the climate crisis rapidly and robustly. And Carbon Market Watch was there, along with allies in the environmental movement, demanding action, exposing inaction and formulating feasible, science-based paths forward.\\n\\nSo how is the world doing?\\n\\nLast year\\u2019s record was a mixed one. Encouragingly, the European Union managed to wind up its mammoth \\u2018Fit for 55\\u2019 package of measures and regulations aimed at slashing 55% off its net carbon footprint by 2030. However, the proof of the pudding was in the testing, and many of the compromise measures proved not to go far enough or to be too unambitious or riddled with loopholes to make a difference.\\n\\nAt the global level, the situation was patchier still. COP28 ended up with no significant new commitments to reduce emissions, though some progress was made on climate finance for developing countries. However, when it came to Article 6 carbon markets, there was deadlock - but this failure avoided a worse outcome.\\n\\nBeyond governments, we also kept an eye on the corporate world and the voluntary carbon market. We not only exposed greenwashing but also scored significant successes in combating outrageous climate claims. We saw self-regulatory initiatives of the voluntary carbon market take important strides towards bringing more integrity to the trade in carbon credits. This change in direction was in part due to the pivotal role of civil society and the media in highlighting the shortcomings of the existing system and exposing foul play where it occurred. Some members of the old \\u2018VCM guard\\u2019 left their posts.\\n\\nThroughout these processes, CMW played its dual role as watchdog and research institute: we analysed the proposals on the table, provided policy recommendations, opposed bad choices and supported good ones. We know how to \\u2018growl\\u2019 at problems but are just as ready to \\u2018wag our tail\\u2019 when we see solutions.\\n\\nIn this annual report, we\\u2019ve compiled the highlights of 2023 and the successes we achieved. We could not have accomplished this without the talent, passion and dedication of our staff. Our team has thrived through its daily cooperation. We have sweated together on fundraising applications and reports, but also on a city cycling tour and a summer dance in the park. We encourage each other to make the best use of our strengths and to honour our convictions in our day-to-day lives. We have been buoyed by the unwavering support of our honorary board, members, funders and allies.\\n\\n**Sabine Frank**\\n\\n**Executive director**\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"page_footer\",\n",
      "      \"content\": \"2023 ANNUAL REPORT 5\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "INFO:root:Processing PDF page 6: Size=(1240, 1754), Mode=RGB\n",
      "INFO:httpx:HTTP Request: POST https://hbai-openai-useast2.openai.azure.com//openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Extracted JSON for page 6: {\n",
      "  \"elements\": [\n",
      "    {\n",
      "      \"type\": \"image\",\n",
      "      \"content\": \"A grayscale image showing a cloudy sky with a plume of smoke rising from industrial chimneys on the right side. The image is overlaid with large, green, curved lines. In the top left corner, there is a small text: 'Photo : Nik Shuliahin on Unsplash'.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "INFO:root:Processing PDF page 7: Size=(1241, 1754), Mode=RGB\n",
      "INFO:httpx:HTTP Request: POST https://hbai-openai-useast2.openai.azure.com//openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Extracted JSON for page 7: {\n",
      "  \"elements\": [\n",
      "    {\n",
      "      \"type\": \"body_text_section\",\n",
      "      \"content\": \"# TABLE OF CONTENTS\\n\\n**FOREWORD**\\nP.5\\n\\n**NOTICEBOARD**\\nP.9\\n\\n**2023: A YEAR IN FIGURES**\\nP.10\\n\\n**CARBON MARKET WATCH IN ACTION**\\n\\nThe human side of emissions trading\\nP.12\\n\\nShelving carbon neutrality at the supermarket\\nP.13\\n\\n2040, the new 2050\\nP.13\\n\\nExposing the EU\\u2019s emissions aristocracy\\nP.14\\n\\nAir traffic control\\nP.15\\n\\nError log raises REDD flags\\nP.15\\n\\nTop of the COPs\\nP.16\\n\\nCertifiably unsound carbon removals\\nP.16\\n\\nShipshape or shipwreck?\\nP.17\\n\\nNot zero\\nP.17\\n\\n**OUR TEAM**\\nP.18\\n\\n**OUR BOARD & MEMBERS**\\nP.24\\n\\n**FINANCE & FUNDERS**\\nP.26\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"page_footer\",\n",
      "      \"content\": \"2023 ANNUAL REPORT 7\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "INFO:root:Processing PDF page 8: Size=(1240, 1754), Mode=RGB\n",
      "INFO:httpx:HTTP Request: POST https://hbai-openai-useast2.openai.azure.com//openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Extracted JSON for page 8: {\n",
      "  \"elements\": [\n",
      "    {\n",
      "      \"type\": \"image\",\n",
      "      \"content\": \"A stylized quote with large, bold text: \\\"Markets must bring tangible benefits for the people\\\". The words \\\"must\\\" and \\\"for\\\" are highlighted in blue ovals. The design includes decorative blue and teal elements around the text.\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"page_footer\",\n",
      "      \"content\": \"8  CARBON MARKET WATCH\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "INFO:root:Processing PDF page 9: Size=(1241, 1754), Mode=RGB\n",
      "INFO:httpx:HTTP Request: POST https://hbai-openai-useast2.openai.azure.com//openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Extracted JSON for page 9: {\n",
      "  \"elements\": [\n",
      "    {\n",
      "      \"type\": \"page_header\",\n",
      "      \"content\": \"# NOTICEBOARD\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"boxout\",\n",
      "      \"content\": \"### DELIA VILLAGRASA\\n**Chair of the board**\\n\\n\\\"Carbon Market Watch\\u2019s work remains essential. For instance, CMW\\u2019s recent report demonstrating that the 2030 climate targets of over 50 top corporations are significantly off track to keep within the 1.5\\u00b0C global heating limit showcases the need for the EU and other regions of the world to accelerate climate action. Carbon Markets, if done right, are one tool to advance on this goal, and CMW\\u2019s work to keep carbon markets effective and clean is key.\\\"\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"boxout\",\n",
      "      \"content\": \"### J\\u00dcRGEN MAIER\\n**Vice chair of the board**\\n\\n\\\"Markets are not an end in themselves - they must bring tangible benefits for the people. If not, people will reject them. Carbon markets are no exception, and that is why we need CMW.\\\"\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"boxout\",\n",
      "      \"content\": \"### ULRIKKA AARNIO\\n**Board member**\\n\\n\\\"Carbon Market Watch continues to stand out as a driving force in ensuring the environmental integrity of the EU\\u2019s climate policies. This year, I am particularly impressed by their pivotal role in shaping the EU\\u2019s carbon dioxide removal policy. Through their tireless advocacy and unparalleled expertise, Carbon Market Watch has played a leading role in shaping the Carbon Removal Certification Framework, solidifying their position as a prominent force within the Brussels CDR landscape.\\\"\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"boxout\",\n",
      "      \"content\": \"### MARTIN PORTER\\n**Board member**\\n\\n\\\"High-quality carbon markets are an essential component of a successful climate transition. They need principled and expert scrutiny to be effective and CMW\\u2019s activities over the past year have again provided this, in the EU as well as beyond.\\\"\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"page_footer\",\n",
      "      \"content\": \"2023 ANNUAL REPORT 9\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "INFO:root:Processing PDF page 10: Size=(1240, 1754), Mode=RGB\n",
      "INFO:httpx:HTTP Request: POST https://hbai-openai-useast2.openai.azure.com//openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Extracted JSON for page 10: {\n",
      "  \"elements\": [\n",
      "    {\n",
      "      \"type\": \"body_text_section\",\n",
      "      \"content\": \"## 2023: A YEAR IN FIGURES\\nA rundown of the year in numbers:\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"image\",\n",
      "      \"content\": \"An abstract design with green and blue curved lines, resembling a stylized graph or chart.\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"chart\",\n",
      "      \"content\": \"### 312,000 views of our website\\nA chart with a grid background, featuring two eye icons and an upward arrow, symbolizing an increase in website views.\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"page_footer\",\n",
      "      \"content\": \"10 CARBON MARKET WATCH\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "INFO:root:Processing PDF page 11: Size=(1241, 1754), Mode=RGB\n",
      "INFO:httpx:HTTP Request: POST https://hbai-openai-useast2.openai.azure.com//openai/deployments/gpt-4o/chat/completions?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Extracted JSON for page 11: {\n",
      "  \"elements\": [\n",
      "    {\n",
      "      \"type\": \"image\",\n",
      "      \"content\": \"An infographic styled as a web browser window with various statistics and icons. \\n\\n- **Top Left:** A bell icon with text: \\\"Over 6,900 new social media followers\\\" and \\\"3,456 media mentions of CMW\\\".\\n- **Top Right:** A calendar icon with \\\"January 21\\\" and text: \\\"6 month ago 5 events organised\\\".\\n- **Middle Right:** An envelope icon with text: \\\"6 month ago 9 editions of the CMW newsletter\\\".\\n- **Center:** A play button icon with text: \\\"9 videos released on YouTube\\\".\\n- **Bottom Right:** A social media post icon with text: \\\"117 articles and publications\\\".\\n- **Bottom Left:** A speech bubble with text: \\\"Media outlets in 101 countries and 37 languages covered CMW\\\".\\n- **Bottom Center:** A magnifying glass icon with text: \\\"11.2 billion combined reach of outlets reporting on CMW\\\".\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"page_footer\",\n",
      "      \"content\": \"2023 ANNUAL REPORT 11\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "INFO:root:Processing PDF page 12: Size=(1240, 1754), Mode=RGB\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/Code/Higher Bar AI/ai-workflows/.venv/lib/python3.11/site-packages/PIL/ImageFile.py:554\u001B[0m, in \u001B[0;36m_save\u001B[0;34m(im, fp, tile, bufsize)\u001B[0m\n\u001B[1;32m    553\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 554\u001B[0m     fh \u001B[38;5;241m=\u001B[39m \u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfileno\u001B[49m()\n\u001B[1;32m    555\u001B[0m     fp\u001B[38;5;241m.\u001B[39mflush()\n",
      "\u001B[0;31mAttributeError\u001B[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConverting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to markdown...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     12\u001B[0m input_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(input_dir, filename)\n\u001B[0;32m---> 13\u001B[0m markdown \u001B[38;5;241m=\u001B[39m \u001B[43mdoc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_markdown\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# write the markdown to the output directory\u001B[39;00m\n\u001B[1;32m     16\u001B[0m output_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_dir, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msplitext(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(filename))[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.md\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Code/Higher Bar AI/ai-workflows/src/ai_workflows/document_utilities.py:99\u001B[0m, in \u001B[0;36mDocumentInterface.convert_to_markdown\u001B[0;34m(self, filepath)\u001B[0m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;124;03mConvert a document to markdown.\u001B[39;00m\n\u001B[1;32m     91\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;124;03m:rtype: str\u001B[39;00m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;66;03m# use internal conversion function\u001B[39;00m\n\u001B[0;32m---> 99\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmd\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Code/Higher Bar AI/ai-workflows/src/ai_workflows/document_utilities.py:225\u001B[0m, in \u001B[0;36mDocumentInterface._convert\u001B[0;34m(self, filepath, to_format, json_context, json_job, json_output_spec, json_output_schema)\u001B[0m\n\u001B[1;32m    221\u001B[0m pdf_converter \u001B[38;5;241m=\u001B[39m PDFDocumentConverter(llm_interface\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm_interface, pdf_image_dpi\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpdf_image_dpi,\n\u001B[1;32m    222\u001B[0m                                      pdf_image_max_bytes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpdf_image_max_bytes)\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m to_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmd\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    224\u001B[0m     \u001B[38;5;66;03m# convert to Markdown\u001B[39;00m\n\u001B[0;32m--> 225\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpdf_converter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpdf_to_markdown\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m to_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjson\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;66;03m# convert directly to JSON\u001B[39;00m\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pdf_converter\u001B[38;5;241m.\u001B[39mpdf_to_json(filepath, json_context, json_job, json_output_spec,\n\u001B[1;32m    229\u001B[0m                                      json_output_schema)\n",
      "File \u001B[0;32m~/Code/Higher Bar AI/ai-workflows/src/ai_workflows/document_utilities.py:818\u001B[0m, in \u001B[0;36mPDFDocumentConverter.pdf_to_markdown\u001B[0;34m(self, pdf_path)\u001B[0m\n\u001B[1;32m    781\u001B[0m         json_output_schema \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124m{\u001B[39m\n\u001B[1;32m    782\u001B[0m \u001B[38;5;124m  \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m$schema\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp://json-schema.org/draft-07/schema#\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\n\u001B[1;32m    783\u001B[0m \u001B[38;5;124m  \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobject\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;124m  \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124madditionalProperties\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m: false\u001B[39m\n\u001B[1;32m    815\u001B[0m \u001B[38;5;124m}\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m    817\u001B[0m         \u001B[38;5;66;03m# process PDF to JSON\u001B[39;00m\n\u001B[0;32m--> 818\u001B[0m         all_dicts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpdf_to_json\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpdf_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson_job\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson_output_spec\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson_output_schema\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    820\u001B[0m         \u001B[38;5;66;03m# aggregate all elements into a single list\u001B[39;00m\n\u001B[1;32m    821\u001B[0m         all_elements \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/Code/Higher Bar AI/ai-workflows/src/ai_workflows/document_utilities.py:686\u001B[0m, in \u001B[0;36mPDFDocumentConverter.pdf_to_json\u001B[0;34m(self, pdf_path, json_context, json_job, json_output_spec, json_output_schema)\u001B[0m\n\u001B[1;32m    683\u001B[0m logging\u001B[38;5;241m.\u001B[39mlog(logging\u001B[38;5;241m.\u001B[39mINFO, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProcessing PDF page \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: Size=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimg\u001B[38;5;241m.\u001B[39msize\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Mode=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimg\u001B[38;5;241m.\u001B[39mmode\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    685\u001B[0m \u001B[38;5;66;03m# construct the prompt with the image\u001B[39;00m\n\u001B[0;32m--> 686\u001B[0m prompt_with_image \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm_interface\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muser_message_with_image\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    687\u001B[0m \u001B[43m    \u001B[49m\u001B[43muser_message\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimage_prompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpdf_image_max_bytes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    688\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcurrent_dpi\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpdf_image_dpi\u001B[49m\u001B[43m)\u001B[49m]\n\u001B[1;32m    689\u001B[0m \u001B[38;5;66;03m# call out to the LLM and process the returned JSON\u001B[39;00m\n\u001B[1;32m    690\u001B[0m response_dict, response_text, error \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm_interface\u001B[38;5;241m.\u001B[39mllm_json_response_with_timeout(\n\u001B[1;32m    691\u001B[0m     prompt\u001B[38;5;241m=\u001B[39mprompt_with_image, json_validation_schema\u001B[38;5;241m=\u001B[39mjson_output_schema)\n",
      "File \u001B[0;32m~/Code/Higher Bar AI/ai-workflows/src/ai_workflows/llm_utilities.py:391\u001B[0m, in \u001B[0;36mLLMInterface.user_message_with_image\u001B[0;34m(self, user_message, image, max_bytes, current_dpi)\u001B[0m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    372\u001B[0m \u001B[38;5;124;03mGenerate a user message with an embedded image.\u001B[39;00m\n\u001B[1;32m    373\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;124;03m:rtype: dict\u001B[39;00m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    390\u001B[0m \u001B[38;5;66;03m# convert image to bytes\u001B[39;00m\n\u001B[0;32m--> 391\u001B[0m image_bytes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_image_bytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPNG\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_bytes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mcurrent_dpi\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurrent_dpi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    394\u001B[0m \u001B[38;5;66;03m# encode image bytes as base64\u001B[39;00m\n\u001B[1;32m    395\u001B[0m image_base64 \u001B[38;5;241m=\u001B[39m base64\u001B[38;5;241m.\u001B[39mb64encode(image_bytes)\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Code/Higher Bar AI/ai-workflows/src/ai_workflows/llm_utilities.py:473\u001B[0m, in \u001B[0;36mLLMInterface.get_image_bytes\u001B[0;34m(image, output_format, max_bytes, current_dpi)\u001B[0m\n\u001B[1;32m    471\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m max_bytes \u001B[38;5;129;01mand\u001B[39;00m dpi:\n\u001B[1;32m    472\u001B[0m     save_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdpi\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m (dpi, dpi)\n\u001B[0;32m--> 473\u001B[0m \u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_byte_arr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msave_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    474\u001B[0m current_bytes \u001B[38;5;241m=\u001B[39m img_byte_arr\u001B[38;5;241m.\u001B[39mgetvalue()\n\u001B[1;32m    476\u001B[0m \u001B[38;5;66;03m# if no max_bytes specified or size is under limit, return the bytes\u001B[39;00m\n",
      "File \u001B[0;32m~/Code/Higher Bar AI/ai-workflows/.venv/lib/python3.11/site-packages/PIL/Image.py:2605\u001B[0m, in \u001B[0;36mImage.save\u001B[0;34m(self, fp, format, **params)\u001B[0m\n\u001B[1;32m   2602\u001B[0m     fp \u001B[38;5;241m=\u001B[39m cast(IO[\u001B[38;5;28mbytes\u001B[39m], fp)\n\u001B[1;32m   2604\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 2605\u001B[0m     \u001B[43msave_handler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2606\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   2607\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m open_fp:\n",
      "File \u001B[0;32m~/Code/Higher Bar AI/ai-workflows/.venv/lib/python3.11/site-packages/PIL/PngImagePlugin.py:1488\u001B[0m, in \u001B[0;36m_save\u001B[0;34m(im, fp, filename, chunk, save_all)\u001B[0m\n\u001B[1;32m   1484\u001B[0m     single_im \u001B[38;5;241m=\u001B[39m _write_multiple_frames(\n\u001B[1;32m   1485\u001B[0m         im, fp, chunk, mode, rawmode, default_image, append_images\n\u001B[1;32m   1486\u001B[0m     )\n\u001B[1;32m   1487\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m single_im:\n\u001B[0;32m-> 1488\u001B[0m     \u001B[43mImageFile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_save\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1489\u001B[0m \u001B[43m        \u001B[49m\u001B[43msingle_im\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mIO\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mbytes\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_idat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1491\u001B[0m \u001B[43m        \u001B[49m\u001B[43m[\u001B[49m\u001B[43mImageFile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Tile\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mzip\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43msingle_im\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrawmode\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1492\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1494\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info:\n\u001B[1;32m   1495\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m info_chunk \u001B[38;5;129;01min\u001B[39;00m info\u001B[38;5;241m.\u001B[39mchunks:\n",
      "File \u001B[0;32m~/Code/Higher Bar AI/ai-workflows/.venv/lib/python3.11/site-packages/PIL/ImageFile.py:558\u001B[0m, in \u001B[0;36m_save\u001B[0;34m(im, fp, tile, bufsize)\u001B[0m\n\u001B[1;32m    556\u001B[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001B[1;32m    557\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mAttributeError\u001B[39;00m, io\u001B[38;5;241m.\u001B[39mUnsupportedOperation) \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m--> 558\u001B[0m     \u001B[43m_encode_tile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbufsize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(fp, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflush\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    560\u001B[0m     fp\u001B[38;5;241m.\u001B[39mflush()\n",
      "File \u001B[0;32m~/Code/Higher Bar AI/ai-workflows/.venv/lib/python3.11/site-packages/PIL/ImageFile.py:584\u001B[0m, in \u001B[0;36m_encode_tile\u001B[0;34m(im, fp, tile, bufsize, fh, exc)\u001B[0m\n\u001B[1;32m    581\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m exc:\n\u001B[1;32m    582\u001B[0m     \u001B[38;5;66;03m# compress to Python file-compatible object\u001B[39;00m\n\u001B[1;32m    583\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 584\u001B[0m         errcode, data \u001B[38;5;241m=\u001B[39m \u001B[43mencoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbufsize\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m:]\n\u001B[1;32m    585\u001B[0m         fp\u001B[38;5;241m.\u001B[39mwrite(data)\n\u001B[1;32m    586\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m errcode:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Comparing Markdown documents\n",
    "\n",
    "The next several sections have code to compare the LLM and no-LLM versions of the Markdown outputs. They are a work-in-progress."
   ],
   "id": "d1e02188ca9ac38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "class MarkdownDiffAnalyzer:\n",
    "    \"\"\"A class to analyze differences between Markdown documents while ignoring formatting.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def strip_markdown(text: str) -> str:\n",
    "        \"\"\"\n",
    "        Remove markdown formatting while preserving the actual text content.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The markdown text to process\n",
    "            \n",
    "        Returns:\n",
    "            str: Text with markdown formatting removed\n",
    "        \"\"\"\n",
    "        \n",
    "        # Remove code blocks and their content\n",
    "        text = re.sub(r'```[\\s\\S]*?```', '', text)\n",
    "        \n",
    "        # Remove inline code\n",
    "        text = re.sub(r'`[^`]*`', '', text)\n",
    "        \n",
    "        # Remove headers\n",
    "        text = re.sub(r'^#{1,6}\\s*', '', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # Remove bold and italic\n",
    "        text = re.sub(r'\\*\\*.*?\\*\\*', lambda m: m.group()[2:-2], text)\n",
    "        text = re.sub(r'\\*.*?\\*', lambda m: m.group()[1:-1], text)\n",
    "        text = re.sub(r'__.*?__', lambda m: m.group()[2:-2], text)\n",
    "        text = re.sub(r'_.*?_', lambda m: m.group()[1:-1], text)\n",
    "        \n",
    "        # Remove links but keep text\n",
    "        text = re.sub(r'\\[([^\\]]+)\\]\\([^\\)]+\\)', r'\\1', text)\n",
    "        \n",
    "        # Remove images\n",
    "        text = re.sub(r'!\\[([^\\]]*)\\]\\([^\\)]+\\)', '', text)\n",
    "        \n",
    "        # Remove horizontal rules\n",
    "        text = re.sub(r'^[-*_]{3,}$', '', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # Remove blockquotes\n",
    "        text = re.sub(r'^\\s*>\\s*', '', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # Remove list markers\n",
    "        text = re.sub(r'^\\s*[-*+]\\s+', '', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'^\\s*\\d+\\.\\s+', '', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # Remove tables\n",
    "        text = re.sub(r'\\|.*\\|', '', text)\n",
    "        text = re.sub(r'^\\s*[-:|\\s]+$', '', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    @staticmethod\n",
    "    def find_missing_chunks(text1: str, text2: str, min_length: int = 10) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Find chunks of text that exist in one document but not the other.\n",
    "        \n",
    "        Args:\n",
    "            text1 (str): First text to compare\n",
    "            text2 (str): Second text to compare\n",
    "            min_length (int): Minimum length of chunks to consider\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[List[str], List[str]]: Lists of chunks unique to text1 and text2\n",
    "        \"\"\"\n",
    "        # Initialize sequence matcher\n",
    "        matcher = SequenceMatcher(None, text1, text2)\n",
    "        \n",
    "        # Get matching blocks\n",
    "        matches = matcher.get_matching_blocks()\n",
    "        \n",
    "        # Find chunks unique to text1\n",
    "        unique_to_1 = []\n",
    "        last_a = 0\n",
    "        for match in matches:\n",
    "            i, j, n = match\n",
    "            if i - last_a >= min_length:\n",
    "                unique_to_1.append(text1[last_a:i].strip())\n",
    "            last_a = i + n\n",
    "            \n",
    "        # Find chunks unique to text2\n",
    "        unique_to_2 = []\n",
    "        last_b = 0\n",
    "        for match in matches:\n",
    "            i, j, n = match\n",
    "            if j - last_b >= min_length:\n",
    "                unique_to_2.append(text2[last_b:j].strip())\n",
    "            last_b = j + n\n",
    "            \n",
    "        return unique_to_1, unique_to_2\n",
    "    \n",
    "    def compare_markdown_docs(self, md1: str, md2: str, min_length: int = 10) -> Dict:\n",
    "        \"\"\"\n",
    "        Compare two Markdown documents and find their differences.\n",
    "        \n",
    "        Args:\n",
    "            md1 (str): First Markdown document\n",
    "            md2 (str): Second Markdown document\n",
    "            min_length (int): Minimum length of different chunks to report\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Dictionary containing analysis results\n",
    "        \"\"\"\n",
    "        # Strip Markdown formatting\n",
    "        clean1 = self.strip_markdown(md1)\n",
    "        clean2 = self.strip_markdown(md2)\n",
    "        \n",
    "        # Find differences\n",
    "        missing_from_2, missing_from_1 = self.find_missing_chunks(clean1, clean2, min_length)\n",
    "        \n",
    "        # Calculate similarity ratio\n",
    "        similarity = SequenceMatcher(None, clean1, clean2).ratio()\n",
    "        \n",
    "        return {\n",
    "            'similarity_ratio': similarity,\n",
    "            'missing_from_doc1': missing_from_1,\n",
    "            'missing_from_doc2': missing_from_2,\n",
    "            'clean_text1': clean1,\n",
    "            'clean_text2': clean2\n",
    "        }"
   ],
   "id": "889206ac9557d25f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import difflib\n",
    "\n",
    "# loop through input files and compare the -no-llm version to the LLM version of the output files\n",
    "for filename in os.listdir(input_dir):\n",
    "    if os.path.isfile(os.path.join(input_dir, filename)) and not filename.startswith('.') and not filename.endswith('.md'):\n",
    "        output_path1 = os.path.join(output_dir, os.path.splitext(os.path.basename(filename))[0] + '.md')\n",
    "        output_path2 = os.path.join(output_dir, os.path.splitext(os.path.basename(filename))[0] + '-no-llm.md')\n",
    "\n",
    "        print(f\"\\n\\nComparing {output_path1} to {output_path2}...\")\n",
    "        with open(output_path1, 'r') as f:\n",
    "            md1 = f.read()\n",
    "        with open(output_path2, 'r') as f:\n",
    "            md2 = f.read()\n",
    "        \n",
    "        results = MarkdownDiffAnalyzer().compare_markdown_docs(md1, md2)\n",
    "        \n",
    "        print(f\"Similarity ratio: {results['similarity_ratio']:.2%}\")\n",
    "        print(\"\\nMissing from document 1 (LLM version):\")\n",
    "        for chunk in results['missing_from_doc1']:\n",
    "            print(f\"- {chunk}\")\n",
    "\n",
    "        print(\"\\nMissing from document 2 (no-LLM version):\")\n",
    "        for chunk in results['missing_from_doc2']:\n",
    "            print(f\"- {chunk}\")\n",
    "        \n",
    "        print(\"\\nDifferences:\")\n",
    "        for line in difflib.unified_diff(md1.splitlines(), md2.splitlines(), fromfile='With LLM', tofile='Without LLM', lineterm=''):\n",
    "            print(line)"
   ],
   "id": "cb34052874464dc9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
